{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c124b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the text file\n",
    "# wget https://www.gutenberg.org/cache/epub/16317/pg16317.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486706fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# all sorts of punctuation to be removed\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114c6b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words ranked from 10th to 20th by frequency:\n",
      "you: 1467\n",
      "for: 1340\n",
      "as: 1202\n",
      "be: 1181\n",
      "not: 1166\n",
      "he: 1075\n",
      "with: 1035\n",
      "his: 1029\n",
      "are: 991\n",
      "i: 956\n",
      "this: 938\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# reading the txt file\n",
    "def read_text(text_file):\n",
    "\n",
    "    # Reading the downloaded text file\n",
    "    with open(text_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw_text = f.read()\n",
    "    \n",
    "    return raw_text\n",
    "\n",
    "# cleaning the data\n",
    "def clean_text(data):\n",
    "\n",
    "    # Converting text to lower case\n",
    "    data = data.lower()\n",
    "\n",
    "    # Deleting all kinds of punctuation, '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    # Make trans uses (replace, replace with, delete)\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "    # Using the translator on the data\n",
    "    data = data.translate(translator)\n",
    "\n",
    "    return data\n",
    "\n",
    "# creating a dictionary for each word\n",
    "def count_word_frequencies(text):\n",
    "\n",
    "    # Splitting the text into words from a string into an array \n",
    "    words = text.split()\n",
    "    freq = {}\n",
    "\n",
    "    # This loops through the words array and creates a dictionary based on each word to count \n",
    "    for word in words:\n",
    "\n",
    "        # if the word is already in the dictionary, then it will add a count of 1\n",
    "        freq[word] = freq.get(word, 0) + 1\n",
    "\n",
    "    return freq\n",
    "\n",
    "# retrieving the count and it's rankings\n",
    "def get_top_words(freq_dict, start_rank, end_rank):\n",
    "\n",
    "    # Sort by frequency (descending)\n",
    "    # lambda x[1] refers to the frequency of each word\n",
    "    sorted_words = sorted(freq_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Slice for 10th to 20th (0-indexed)\n",
    "    return sorted_words[start_rank - 1:end_rank]\n",
    "\n",
    "\n",
    "def main(freq_from, freq_to, text_file):\n",
    "\n",
    "    # reading text file\n",
    "    raw_text = read_text(text_file)\n",
    "\n",
    "    # checking if the text file is empty\n",
    "    if raw_text==\"\":\n",
    "        return print(\"Empty string in text file\")\n",
    "    \n",
    "    # processing the text file\n",
    "    cleaned_text = clean_text(raw_text)\n",
    "\n",
    "    # coutnign the number of words in the text file\n",
    "    frequencies = count_word_frequencies(cleaned_text)\n",
    "\n",
    "    # gettign the number of words\n",
    "    top_words = get_top_words(frequencies, freq_from, freq_to)\n",
    "\n",
    "    print(f\"Words ranked from {freq_from}th to {freq_to}th by frequency:\")\n",
    "    for word, count in top_words:\n",
    "        print(f\"{word}: {count}\")\n",
    "\n",
    "freq_from = 10\n",
    "freq_to = 20\n",
    "text_file = \"pg16317.txt\"\n",
    "\n",
    "main(freq_from, freq_to, text_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e65484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
